{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CDS py ry hy sklearn classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdIthVyRmdJ_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as numpy\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp_aJuYrnZKW",
        "outputId": "dae157b7-fde4-4de1-b3ec-9a97f6add34c"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "train_data = pd.read_csv('masterfile.csv') # Load training data\n",
        "test_data = pd.read_csv('mastertestfile.csv') # Load test data\n",
        "train_data = shuffle(train_data)\n",
        "\n",
        "print(train_data)\n",
        "print(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                r_arm  ...                 file\n",
            "7   [172.62, 170.52, 171.35, 171.26, 172.7, 172.02...  ...  20211024_222035.mp4\n",
            "53  [173.89, 175.34, 174.72, 173.41, 172.69, 172.8...  ...         Good PY3.mp4\n",
            "4   [162.02, 162.32, 163.42, 163.67, 162.9, 164.1,...  ...  20211024_221859.mp4\n",
            "19  [166.55, 166.54, 162.52, 160.17, 159.46, 151.0...  ...          PY Bad2.mp4\n",
            "52  [175.41, 177.45, 175.5, 173.95, 172.03, 173.82...  ...         Good PY2.mp4\n",
            "..                                                ...  ...                  ...\n",
            "66  [283.32, 289.33, 289.23, 296.73, 299.68, 304.1...  ...        ry_good_3.MOV\n",
            "58  [174.98, 173.59, 174.23, 174.2, 174.24, 173.53...  ...         Good PY8.mp4\n",
            "1   [163.26, 164.05, 164.12, 164.52, 164.86, 164.8...  ...  20211024_221843.mp4\n",
            "38  [164.94, 164.74, 164.36, 164.71, 164.3, 164.31...  ...  20211024_221812.mp4\n",
            "33  [109.08, 79.11, 85.66, 93.44, 84.1, 80.3, 80.5...  ...         ry_bad_6.MOV\n",
            "\n",
            "[73 rows x 8 columns]\n",
            "                                               r_arm  ...        file\n",
            "0  [188.87, 185.87, 187.55, 189.42, 188.92, 187.1...  ...   Bad 2.mov\n",
            "1  [113.88, 115.59, 115.81, 118.06, 118.72, 117.3...  ...   Bad 3.mov\n",
            "2  [168.59, 174.09, 177.19, 177.82, 176.28, 178.9...  ...   Bad 4.mov\n",
            "3  [198.03, 200.95, 199.05, 194.98, 196.0, 195.2,...  ...   Bad 5.mov\n",
            "4  [183.64, 187.43, 189.21, 190.4, 190.73, 192.38...  ...   Bad 6.mov\n",
            "5  [193.52, 192.61, 200.98, 197.74, 195.42, 191.1...  ...     Bad.mov\n",
            "6  [179.7, 175.25, 179.9, 176.15, 176.21, 176.02,...  ...  Good 2.mov\n",
            "7  [340.44, 340.41, 55.89, 8.08, 276.78, 9.17, 29...  ...  Good 3.mov\n",
            "\n",
            "[8 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko_JmJrinyRI",
        "outputId": "c6e0390c-10d3-4849-f9e1-46825fe59b7a"
      },
      "source": [
        "# Split up the data to x and y \n",
        "\n",
        "X_train = train_data.drop(['file','class'],1)\n",
        "y_train = train_data['class']\n",
        "\n",
        "X_test = test_data.drop(['file','class'],1)\n",
        "y_test = test_data['class']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7     0\n",
            "53    1\n",
            "4     0\n",
            "19    0\n",
            "52    1\n",
            "     ..\n",
            "66    1\n",
            "58    1\n",
            "1     0\n",
            "38    1\n",
            "33    0\n",
            "Name: class, Length: 73, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtjqiNISoWym",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "dc6dcabb-4841-45f4-fe3b-31c6b8dc2679"
      },
      "source": [
        "# Use normalization \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = MinMaxScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train,y_train) #fit X and y training sets\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-90b0d0d86551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# fit the normalization on the training set:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mx_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#fit X and y training sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# then create new and normalized training/test sets:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    371\u001b[0m         X = check_array(X,\n\u001b[1;32m    372\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                         force_all_finite=\"allow-nan\")\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1781\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '[172.62, 170.52, 171.35, 171.26, 172.7, 172.02, 171.89, 171.22, 170.15, 170.15, 170.12, 169.67, 169.74, 169.74, 169.74, 169.84, 169.84, 170.57, 170.59, 170.2, 170.2, 170.17, 170.17, 170.08, 170.08, 169.35, 168.85, 167.42, 166.41, 163.59, 161.75, 158.15, 153.53, 149.37, 143.14, 136.82, 129.81, 124.76, 117.38, 110.29, 104.2, 98.37, 92.66, 86.57, 83.95, 77.21, 75.99, 75.12, 75.99, 81.14, 83.95, 88.06, 100.62, 104.93, 109.66, 116.02, 122.29, 129.68, 136.15, 141.38, 146.94, 154.33, 159.82, 164.16, 166.28, 167.66, 168.88, 170.31, 170.18, 170.39, 170.68, 170.58, 171.07, 171.1, 171.0, 171.0, 170.51, 170.48, 171.21, 171.21, 171.97, 172.21, 171.43, 171.96, 171.91, 172.24, 172.24, 171.85, 171.85, 172.62, 172.51, 173.25, 172.85]'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biMMXULHp26U"
      },
      "source": [
        "### Define a evaluation metric\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDw4EjEvp2XI"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "def evaluate_on_training_set(y_test, y_pred):\n",
        "  # Calculate AUC\n",
        "  print(\"AUC is: \", roc_auc_score(y_test, y_pred), \"\\n\")\n",
        "\n",
        "  # print out recall and precision\n",
        "  print(classification_report(y_test, y_pred))\n",
        "\n",
        "  # print out confusion matrix\n",
        "  print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
        "  \n",
        "  # # calculate points for ROC curve\n",
        "  fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "  \n",
        "  # Plot ROC curve\n",
        "  plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc_score(y_test, y_pred))\n",
        "  plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.ylim([0.0, 1.0])\n",
        "  plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
        "  plt.ylabel('True Positive Rate or (Sensitivity)')\n",
        "  plt.title('Receiver Operating Characteristic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O08stMVpYAA"
      },
      "source": [
        "### Using Decision trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "Hf9-n3AMpVvP",
        "outputId": "ba22e209-ed57-4664-9d63-8377bcd06186"
      },
      "source": [
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = tree.DecisionTreeClassifier(max_depth=10,min_samples_leaf=1)\n",
        "# Using default parameters\n",
        "\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "y_pred = model.predict(X_test) # Predicting labels for our test set using model\n",
        "print (y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using new function"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-43752a830d1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Using default parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Predicting labels for our test set using model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1781\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '[172.62, 170.52, 171.35, 171.26, 172.7, 172.02, 171.89, 171.22, 170.15, 170.15, 170.12, 169.67, 169.74, 169.74, 169.74, 169.84, 169.84, 170.57, 170.59, 170.2, 170.2, 170.17, 170.17, 170.08, 170.08, 169.35, 168.85, 167.42, 166.41, 163.59, 161.75, 158.15, 153.53, 149.37, 143.14, 136.82, 129.81, 124.76, 117.38, 110.29, 104.2, 98.37, 92.66, 86.57, 83.95, 77.21, 75.99, 75.12, 75.99, 81.14, 83.95, 88.06, 100.62, 104.93, 109.66, 116.02, 122.29, 129.68, 136.15, 141.38, 146.94, 154.33, 159.82, 164.16, 166.28, 167.66, 168.88, 170.31, 170.18, 170.39, 170.68, 170.58, 171.07, 171.1, 171.0, 171.0, 170.51, 170.48, 171.21, 171.21, 171.97, 172.21, 171.43, 171.96, 171.91, 172.24, 172.24, 171.85, 171.85, 172.62, 172.51, 173.25, 172.85]'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GbjStFHqwsW"
      },
      "source": [
        "### Using KNN Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL-rAlodqi0n"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors=20) # Define the model with parameters\n",
        "model.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "# Evaluate the model: \n",
        "y_pred = model.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "print (y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu0MBP0CuFgH"
      },
      "source": [
        "### Using logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WET7A5elraFr"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(C=1.0, multi_class='auto', solver='liblinear') #(regularization parameter, detect classes auto, optimzation algorithm )\n",
        "# Define the model with parameters\n",
        "\n",
        "model.fit(X_train_norm, y_train) # Training the model\n",
        "y_pred = model.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blgb2TYDuOQL"
      },
      "source": [
        "### Using Gaussian NB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPG2MIgsuFB4"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB() # Define the model with parameters\n",
        "\n",
        "model.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wn6CElOuao5"
      },
      "source": [
        "### Using SVM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtNung8quWIK"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "model = SVC(C=10, gamma='auto', kernel='linear')\n",
        "\n",
        "model.fit(X_train_norm, y_train) # Training SVM\n",
        "\n",
        "y_pred = model.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzLolMp8ue7-"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "tuned_parameters = [{'kernel': ['rbf'], #radial basis function\n",
        "                     'gamma': [1e-3, 1e-4],\n",
        "                     'C': [1, 10, 100]},\n",
        "                    {'kernel': ['linear'],\n",
        "                     'C': [1, 10, 100]}]\n",
        "\n",
        "# we define the grid search model for SVM: \n",
        "clf = GridSearchCV(SVC(), tuned_parameters, cv=2,\n",
        "                   scoring='roc_auc', verbose=1, n_jobs=4)\n",
        "\n",
        "# train the model on the training set: \n",
        "clf.fit(X_train_norm, y_train)\n",
        "\n",
        "# Show best parameters: \n",
        "print(\"Best parameter set found on development set:\")\n",
        "print(clf.best_params_, '\\n')\n",
        "\n",
        "y_pred = clf.predict(X_test_norm) #create predictions\n",
        "evaluate_on_training_set(y_test, y_pred) # evaluate like we always do"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5byesG-9vWvn"
      },
      "source": [
        "### Using AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymLRPMn7u68K"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "model = AdaBoostClassifier(n_estimators=10000, learning_rate=0.01) # Define the model with parameters\n",
        "\n",
        "model.fit(X_train, y_train) # Training the model\n",
        "y_pred = model.predict(X_test) # Predicting labels for our test set using trained model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmVn0p15wXjl"
      },
      "source": [
        "### Using RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a0nn1KrwZcH"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators = 50) # Define the model\n",
        "\n",
        "#TODO fit the model, predict y and evaluate as before\n",
        "model.fit(X_train_norm,y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHXkd5x9wOzF"
      },
      "source": [
        "### Using all\n",
        "\n",
        "Tune parameters in this part to get best accuracy on classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS-nMNLhvch4"
      },
      "source": [
        "# 5. Train and evaluate multiple models (decision tree, svm with grid search, logistic regression, embedded models) to find the best classifier.\n",
        "\n",
        "from scipy._lib.six import iteritems\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "\n",
        "tuned_parameters = [{'kernel': ['rbf'], \n",
        "                     'gamma': [1e-3, 1e-4],\n",
        "                     'C': [1, 10, 100]},\n",
        "                    {'kernel': ['liblinear'],\n",
        "                     'C': [1, 10, 100]}]\n",
        "model_dict = {\n",
        "             'Decision Tree' : DecisionTreeClassifier(max_depth=3,min_samples_leaf=1),\n",
        "              'KNN' :KNeighborsClassifier(n_neighbors = 15),\n",
        "              'Logistic Regression' : LogisticRegression(C=1.0,multi_class='auto',solver='sag'), #vary solver\n",
        "              'Naive Bayes Gaussian': GaussianNB(),\n",
        "              'SVM' : SVC(C=10,gamma='auto',kernel='rbf'), #vary kernel\n",
        "              'SVM w Grid Search': GridSearchCV(SVC(),tuned_parameters,cv=2,verbose = 1, n_jobs = 4), #Tweak tuned_parameters\n",
        "              'Ensemble models' : AdaBoostClassifier(n_estimators = 100,learning_rate = 0.1,random_state=0), #vary learning_rate, n_estimators is large enough \n",
        "              'Random Forest' : RandomForestClassifier(n_estimators = 50,oob_score = True), #Vary n_estimators\n",
        "              'MLP Classifier' : MLPClassifier(hidden_layer_sizes = [100]*5,random_state = 1,max_iter = 300), #USING NEURAL NETWORKS, depth 100, width 5\n",
        "              'Gradient Booster': GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,max_depth=1, random_state=0),\n",
        "              'Stochastic Gradient Descent classifier': SGDClassifier(loss='modified_huber',shuffle=True,random_state=101)\n",
        "        }\n",
        "\n",
        "score_matrix_dict = {             \n",
        "              'Decision Tree' : [],\n",
        "              'KNN' : [],\n",
        "              'Logistic Regression' :[], \n",
        "              'Naive Bayes Gaussian': [], \n",
        "              'SVM' : [],\n",
        "              'SVM w Grid Search': [],\n",
        "              'Ensemble models' : [],\n",
        "              'Random Forest' : [],\n",
        "              'MLP Classifier' : [],\n",
        "              'Gradient Booster' : [],\n",
        "              'Stochastic Gradient Descent classifier' : []\n",
        "}\n",
        "\n",
        "max_score = 0\n",
        "\n",
        "# IMPORTANT: Evaluate only in terms of classification_report and confusion matrix. (No need for AUC and ROC here, as we are doing multiclass classification, the target label would need to be binarized first, which we are not doing.)\n",
        "\n",
        "# run through each model in the list, use X_train_norm\n",
        "for key,value in model_dict.items():\n",
        "  model_norm = value #assigning a model to norm values\n",
        "\n",
        "  model_norm.fit(X_train_norm,y_train)\n",
        "\n",
        "  y_pred_norm = model_norm.predict(X_test_norm)\n",
        "  \n",
        "  score_matrix_dict[key].append(confusion_matrix(y_test,y_pred_norm)) #store the confusion matrix\n",
        "  score_matrix_dict[key].append(accuracy_score(y_test,y_pred_norm))\n",
        "  score_matrix_dict[key].append(classification_report(y_test,y_pred_norm))\n",
        "  \n",
        "  print(key)\n",
        "  print(classification_report(y_test,y_pred_norm))\n",
        "  print(\"\\n\")\n",
        "  # evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function\n",
        "  \n",
        "print(score_matrix_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeswsthIxCmr"
      },
      "source": [
        "### Using cross val\n",
        "\n",
        "Model checking only, not used for model building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY8gAJTGxFX9"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
        "\n",
        "# Change solver accordingly\n",
        "# solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
        "clf = LogisticRegressionCV(solver='liblinear')\n",
        "\n",
        "pipeline = Pipeline([('transformer', MinMaxScaler()), ('estimator', clf)])\n",
        "\n",
        "\n",
        "scores = cross_val_score(pipeline, X_train_norm, y_train, cv=10)\n",
        "AUCscores = cross_val_score(pipeline, X_train_norm, y_train, cv=10, scoring='roc_auc')\n",
        "\n",
        "\n",
        "print('The accuracy of each fold: ')\n",
        "print(scores)\n",
        "\n",
        "print ('Average accuracy across folds: ' + str(scores.mean()))\n",
        "\n",
        "\n",
        "print('The AUC of each fold: ')\n",
        "print(AUCscores)\n",
        "\n",
        "print ('Average AUC across folds: ' + str(AUCscores.mean()))\n",
        "\n",
        "\n",
        "print('Final confusion matrix: ')\n",
        "y_pred = cross_val_predict(pipeline, X_train_norm, y_train, cv=10)\n",
        "conf_mat = confusion_matrix(y_train, y_pred)\n",
        "\n",
        "print(conf_mat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WrF2yYZxF-u"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
        "\n",
        "\n",
        "best_model = DecisionTreeClassifier(max_depth=3,min_samples_leaf=1)\n",
        "\n",
        "pipeline = Pipeline([('transformer', MinMaxScaler()), ('estimator', best_model)])\n",
        "\n",
        "\n",
        "scores = cross_val_score(pipeline, X_train_norm, y_train, cv=10) #10-fold cross val\n",
        "AUCscores = cross_val_score(pipeline, X_train_norm, y_train, cv=10, scoring='roc_auc')\n",
        "\n",
        "\n",
        "print('The accuracy of each fold: ')\n",
        "print(scores)\n",
        "\n",
        "print ('Average accuracy across folds: ' + str(scores.mean()))\n",
        "\n",
        "\n",
        "print('The AUC of each fold: ')\n",
        "print(AUCscores)\n",
        "\n",
        "print ('Average AUC across folds: ' + str(AUCscores.mean()))\n",
        "\n",
        "\n",
        "print('Final confusion matrix: ')\n",
        "y_pred = cross_val_predict(pipeline, X_train_norm, y_train, cv=10)\n",
        "conf_mat = confusion_matrix(y_train, y_pred)\n",
        "\n",
        "print(conf_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puuq-cGszL6d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}