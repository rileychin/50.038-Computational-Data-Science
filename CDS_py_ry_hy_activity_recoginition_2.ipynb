{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CDS_py_ry_hy_direct_video_classifier_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpKNXKabHwf7"
      },
      "source": [
        "# https://keras.io/examples/vision/video_classification/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HweLHQIHJi1"
      },
      "source": [
        "### Importing and preparing dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tqPhsNJyQ46",
        "outputId": "8a6b0a42-7b1d-44a6-c50b-0f86d147306a"
      },
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4zrBUpM3zPL"
      },
      "source": [
        "!rm -rf sample_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W29darr8tVu",
        "outputId": "35dd8d7a-8faf-4f29-b3fa-68261e6640a1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFd2nRiX-Pim"
      },
      "source": [
        "datapath = '/content/gdrive/MyDrive/data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xZnYEiEx-8Z"
      },
      "source": [
        "from tensorflow_docs.vis import embed\n",
        "from tensorflow import keras\n",
        "from imutils import paths\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2MhdKMvyzid"
      },
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "\n",
        "MAX_SEQ_LENGTH = 20\n",
        "NUM_FEATURES = 2048"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqdykdjvzIZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b70f598-a732-4cbf-901a-869cd6286493"
      },
      "source": [
        "# open the file which have names of training videos\n",
        "from os import listdir\n",
        "from os.path import isfile,join\n",
        "\n",
        "bc = [f for f in listdir(f\"{datapath}goodtrain\") if isfile(join(f\"{datapath}goodtrain\",f))]\n",
        "sp = [f for f in listdir(f\"{datapath}ShoulderPressGoodTrain\") if isfile(join(f\"{datapath}ShoulderPressGoodTrain\",f))]\n",
        "allvideos = bc+sp\n",
        "\n",
        "videoclass = ['bicep_curl' for _ in range(len(bc))] + ['shoulder_press' for _ in range(len(sp))]\n",
        "\n",
        "# creating a dataframe having video names\n",
        "train = pd.DataFrame({'video_name':allvideos})\n",
        "train['class'] = videoclass\n",
        "\n",
        "print(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             video_name           class\n",
            "0   20211024_221804.mp4      bicep_curl\n",
            "1   20211024_221812.mp4      bicep_curl\n",
            "2   20211024_221818.mp4      bicep_curl\n",
            "3   20211024_221824.mp4      bicep_curl\n",
            "4   20211024_221830.mp4      bicep_curl\n",
            "..                  ...             ...\n",
            "81  20211122_222039.mp4  shoulder_press\n",
            "82  20211122_222028.mp4  shoulder_press\n",
            "83  20211122_222033.mp4  shoulder_press\n",
            "84  20211122_222021.mp4  shoulder_press\n",
            "85  20211122_222105.mp4  shoulder_press\n",
            "\n",
            "[86 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLbJi1t7zyCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73037f1f-9772-4a30-a1b6-11db6d3176c3"
      },
      "source": [
        "# open the .txt file which have names of test videos\n",
        "from os import listdir\n",
        "from os.path import isfile,join\n",
        "\n",
        "bctest = [f for f in listdir(f\"{datapath}goodtest\") if isfile(join(f\"{datapath}goodtest\",f))]\n",
        "sptest = [f for f in listdir(f\"{datapath}ShoulderPressGoodTest\") if isfile(join(f\"{datapath}ShoulderPressGoodTest\",f))]\n",
        "alltest = bctest+sptest\n",
        "\n",
        "testclass = ['bicep_curl' for _ in range(len(bctest))] + ['shoulder_press' for _ in range(len(sptest))]\n",
        "\n",
        "# creating a dataframe having video names\n",
        "test = pd.DataFrame({'video_name':alltest})\n",
        "test['class'] = testclass\n",
        "\n",
        "print(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       video_name           class\n",
            "0      Good 2.mov      bicep_curl\n",
            "1      Good 3.mp3      bicep_curl\n",
            "2      Good 6.mov      bicep_curl\n",
            "3      Good 7.mov      bicep_curl\n",
            "4      Good 1.mov      bicep_curl\n",
            "5      Good 8.mov      bicep_curl\n",
            "6      Good 9.mov      bicep_curl\n",
            "7      Good 4.mov      bicep_curl\n",
            "8     Good 10.mov      bicep_curl\n",
            "9     Good 12.mov      bicep_curl\n",
            "10    Good 11.mov      bicep_curl\n",
            "11    Good 13.mov      bicep_curl\n",
            "12  SP good 1.mov  shoulder_press\n",
            "13  SP good 2.mov  shoulder_press\n",
            "14  SP good 3.mov  shoulder_press\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsDGz1MEG4jA"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usHh8hWc0Rml"
      },
      "source": [
        "def load_video(path, i, max_frames=0):\n",
        "    if path == \"train\":\n",
        "        videoname = train['video_name'][i]\n",
        "        videoclass = train['class'][i]\n",
        "        if videoclass == \"bicep_curl\":\n",
        "          videotype = \"goodT\"\n",
        "        elif videoclass == \"shoulder_press\":\n",
        "          videotype = \"ShoulderPressGoodT\"\n",
        "        video = datapath+videotype+\"rain/\"+videoname\n",
        "\n",
        "    elif path == \"test\":\n",
        "        videoname = test['video_name'][i]\n",
        "        videoclass = test['class'][i]\n",
        "        if videoclass == \"bicep_curl\":\n",
        "          videotype = \"goodT\"\n",
        "        elif videoclass == \"shoulder_press\":\n",
        "          videotype = \"ShoulderPressGoodT\"\n",
        "        video = datapath+videotype+\"est/\"+videoname\n",
        "    cap = cv2.VideoCapture(video)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frameID = cap.get(1)\n",
        "            if (frameID%2==0):\n",
        "                frame = cv2.resize(frame, (224, 224))\n",
        "                frames.append(frame)\n",
        "            # storing the frames in a new folder named train_1\n",
        "            # filename = f\"{path}_1/{train['video_name'][i]}_frame{frameID/2}_{train['class'][i]}.jpg\"\n",
        "            # cv2.imwrite(filename, frame)\n",
        "            # if len(frames) == max_frames:\n",
        "            #     break\n",
        "    finally:\n",
        "        cap.release()\n",
        "    return np.array(frames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV2uWmkk1sUp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b7f17c5-9f5a-41ea-8341-3b24d6644227"
      },
      "source": [
        "def build_feature_extractor():\n",
        "    feature_extractor = keras.applications.InceptionV3(\n",
        "        weights=\"imagenet\",\n",
        "        include_top=False,\n",
        "        pooling=\"avg\",\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    )\n",
        "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
        "\n",
        "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "    preprocessed = preprocess_input(inputs)\n",
        "\n",
        "    outputs = feature_extractor(preprocessed)\n",
        "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
        "\n",
        "\n",
        "feature_extractor = build_feature_extractor()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "87924736/87910968 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX8q_AsV2xMh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5b0c3e2-fa8e-467f-f701-247400cfb1d1"
      },
      "source": [
        "label_processor = keras.layers.StringLookup(\n",
        "    num_oov_indices=0, vocabulary=np.unique(train['class'])\n",
        ")\n",
        "print(label_processor.get_vocabulary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bicep_curl', 'shoulder_press']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEMYf5rK3QDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecad072d-cc6b-4596-86d2-27476e613fbe"
      },
      "source": [
        "def prepare_all_videos(df, root_dir):\n",
        "    num_samples = len(df)\n",
        "    video_paths = df[\"video_name\"].values.tolist()\n",
        "    labels = df[\"class\"].values\n",
        "    labels = label_processor(labels[..., None]).numpy()\n",
        "\n",
        "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
        "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
        "    # masked with padding or not.\n",
        "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
        "    frame_features = np.zeros(\n",
        "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
        "    )\n",
        "\n",
        "    # For each video.\n",
        "    for idx, path in enumerate(video_paths):\n",
        "        # Gather all its frames and add a batch dimension.\n",
        "        # print(os.path.join(datapath, \"bad\"+ root_dir, path))\n",
        "        frames = load_video(root_dir, idx)\n",
        "        # frames2 = load_video(os.path.join(datapath, \"bad\"+root_dir, path), idx)\n",
        "        frames = frames[None, ...]\n",
        "        # print(frames)\n",
        "\n",
        "        # Initialize placeholders to store the masks and features of the current video.\n",
        "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "        temp_frame_features = np.zeros(\n",
        "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
        "        )\n",
        "\n",
        "        # Extract features from the frames of the current video.\n",
        "        for i, batch in enumerate(frames):\n",
        "            video_length = batch.shape[0]\n",
        "            length = min(MAX_SEQ_LENGTH, video_length)\n",
        "            for j in range(length):\n",
        "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
        "                    batch[None, j, :]\n",
        "                )\n",
        "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
        "\n",
        "        frame_features[idx,] = temp_frame_features.squeeze()\n",
        "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
        "\n",
        "    return (frame_features, frame_masks), labels\n",
        "\n",
        "\n",
        "train_data, train_labels = prepare_all_videos(train, \"train\")\n",
        "test_data, test_labels = prepare_all_videos(test, \"test\")\n",
        "\n",
        "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
        "print(f\"Frame masks in train set: {train_data[1].shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frame features in train set: (86, 20, 2048)\n",
            "Frame masks in train set: (86, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G38AYHXLCvEZ",
        "outputId": "58b2bac1-200a-49b3-e13a-9a77b9f924a0"
      },
      "source": [
        "# Utility for our sequence model.\n",
        "def get_sequence_model():\n",
        "    class_vocab = label_processor.get_vocabulary()\n",
        "\n",
        "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
        "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "\n",
        "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
        "    # https://keras.io/api/layers/recurrent_layers/gru/\n",
        "    x = keras.layers.GRU(16, return_sequences=True)(\n",
        "        frame_features_input, mask=mask_input\n",
        "    )\n",
        "    x = keras.layers.GRU(8)(x)\n",
        "    x = keras.layers.Dropout(0.4)(x)\n",
        "    x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
        "    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n",
        "\n",
        "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
        "\n",
        "    rnn_model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return rnn_model\n",
        "\n",
        "\n",
        "# Utility for running experiments.\n",
        "def run_experiment():\n",
        "    filepath = \"/tmp/video_classifier\"\n",
        "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
        "    )\n",
        "\n",
        "    seq_model = get_sequence_model()\n",
        "    history = seq_model.fit(\n",
        "        [train_data[0], train_data[1]],\n",
        "        train_labels,\n",
        "        validation_split=0.3,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=[checkpoint],\n",
        "    )\n",
        "\n",
        "    seq_model.load_weights(filepath)\n",
        "    _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history, seq_model\n",
        "\n",
        "\n",
        "_, sequence_model = run_experiment()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/2 [==============>...............] - ETA: 7s - loss: 0.5909 - accuracy: 0.9688\n",
            "Epoch 00001: val_loss improved from inf to 0.10581, saving model to /tmp/video_classifier\n",
            "2/2 [==============================] - 10s 3s/step - loss: 0.5609 - accuracy: 0.7000 - val_loss: 0.1058 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4814 - accuracy: 0.9688\n",
            "Epoch 00002: val_loss improved from 0.10581 to 0.08955, saving model to /tmp/video_classifier\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.4793 - accuracy: 0.9833 - val_loss: 0.0895 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4850 - accuracy: 1.0000\n",
            "Epoch 00003: val_loss improved from 0.08955 to 0.08285, saving model to /tmp/video_classifier\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.4583 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5437 - accuracy: 0.9688\n",
            "Epoch 00004: val_loss improved from 0.08285 to 0.07467, saving model to /tmp/video_classifier\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.4801 - accuracy: 0.9833 - val_loss: 0.0747 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4439 - accuracy: 1.0000\n",
            "Epoch 00005: val_loss improved from 0.07467 to 0.06743, saving model to /tmp/video_classifier\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.4536 - accuracy: 1.0000 - val_loss: 0.0674 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4093 - accuracy: 1.0000\n",
            "Epoch 00006: val_loss improved from 0.06743 to 0.06207, saving model to /tmp/video_classifier\n",
            "2/2 [==============================] - 1s 496ms/step - loss: 0.4404 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4105 - accuracy: 1.0000\n",
            "Epoch 00007: val_loss improved from 0.06207 to 0.05837, saving model to /tmp/video_classifier\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.4588 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4225 - accuracy: 1.0000\n",
            "Epoch 00008: val_loss improved from 0.05837 to 0.05573, saving model to /tmp/video_classifier\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 0.4634 - accuracy: 1.0000 - val_loss: 0.0557 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4173 - accuracy: 1.0000\n",
            "Epoch 00009: val_loss improved from 0.05573 to 0.05293, saving model to /tmp/video_classifier\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 0.4494 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4180 - accuracy: 1.0000\n",
            "Epoch 00010: val_loss improved from 0.05293 to 0.04993, saving model to /tmp/video_classifier\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 0.4402 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5487 - accuracy: 1.0000\n",
            "Test accuracy: 100.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRtOZsM7Gkg7"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQKmKOkxPSXs",
        "outputId": "4a52c685-bc61-4a73-9c29-ea491bcb88f7"
      },
      "source": [
        "def prepare_single_video(frames):\n",
        "    frames = frames[None, ...]\n",
        "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
        "\n",
        "    for i, batch in enumerate(frames):\n",
        "        video_length = batch.shape[0]\n",
        "        length = min(MAX_SEQ_LENGTH, video_length)\n",
        "        for j in range(length):\n",
        "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
        "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
        "\n",
        "    return frame_features, frame_mask\n",
        "\n",
        "\n",
        "def sequence_prediction(i):\n",
        "    class_vocab = label_processor.get_vocabulary()\n",
        "\n",
        "    frames = load_video(\"test\", i)\n",
        "    frame_features, frame_mask = prepare_single_video(frames)\n",
        "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
        "\n",
        "    for i in np.argsort(probabilities)[::-1]:\n",
        "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
        "    return frames\n",
        "\n",
        "\n",
        "for idx, video in enumerate(test[\"video_name\"].values.tolist()):\n",
        "    print(f\"Test video path: {video}\")\n",
        "    test_frames = sequence_prediction(idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test video path: Good 2.mov\n",
            "  bicep_curl: 51.00%\n",
            "  shoulder_press: 49.00%\n",
            "Test video path: Good 3.mp3\n",
            "  bicep_curl: 51.00%\n",
            "  shoulder_press: 49.00%\n",
            "Test video path: Good 6.mov\n",
            "  bicep_curl: 51.00%\n",
            "  shoulder_press: 49.00%\n",
            "Test video path: Good 7.mov\n",
            "  bicep_curl: 51.00%\n",
            "  shoulder_press: 49.00%\n",
            "Test video path: Good 1.mov\n",
            "  bicep_curl: 51.00%\n",
            "  shoulder_press: 49.00%\n",
            "Test video path: Good 8.mov\n",
            "  bicep_curl: 51.00%\n",
            "  shoulder_press: 49.00%\n",
            "Test video path: Good 9.mov\n",
            "  bicep_curl: 51.00%\n",
            "  shoulder_press: 49.00%\n",
            "Test video path: Good 4.mov\n",
            "  bicep_curl: 51.00%\n",
            "  shoulder_press: 49.00%\n",
            "Test video path: Good 10.mov\n",
            "  bicep_curl: 51.00%\n",
            "  shoulder_press: 49.00%\n",
            "Test video path: Good 12.mov\n",
            "  bicep_curl: 51.00%\n",
            "  shoulder_press: 49.00%\n",
            "Test video path: Good 11.mov\n",
            "  bicep_curl: 51.00%\n",
            "  shoulder_press: 49.00%\n",
            "Test video path: Good 13.mov\n",
            "  bicep_curl: 51.00%\n",
            "  shoulder_press: 49.00%\n",
            "Test video path: SP good 1.mov\n",
            "  shoulder_press: 95.16%\n",
            "  bicep_curl:  4.84%\n",
            "Test video path: SP good 2.mov\n",
            "  shoulder_press: 95.06%\n",
            "  bicep_curl:  4.94%\n",
            "Test video path: SP good 3.mov\n",
            "  shoulder_press: 95.12%\n",
            "  bicep_curl:  4.88%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_put52pvE9zI"
      },
      "source": [
        "# def sequence_prediction(path, i):\n",
        "#     class_vocab = label_processor.get_vocabulary()\n",
        "\n",
        "#     # frames = load_video(os.path.join(\"test\", path), i)\n",
        "#     test_data, test_labels = prepare_all_videos(test, \"test\")\n",
        "#     probabilities = sequence_model.predict(test_data)[0]\n",
        "\n",
        "#     for i in np.argsort(probabilities)[::-1]:\n",
        "#         print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
        "#     # return frames\n",
        "\n",
        "# for idx, video in enumerate(test[\"video_name\"].values.tolist()):\n",
        "#     print(f\"Test video path: {video}\")\n",
        "#     test_frames = sequence_prediction(video, idx)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}