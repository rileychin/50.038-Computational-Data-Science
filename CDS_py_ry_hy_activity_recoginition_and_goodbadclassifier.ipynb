{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CDS_py_ry_hy_activity_recoginition_and_goodbadclassifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpKNXKabHwf7"
      },
      "source": [
        "# https://keras.io/examples/vision/video_classification/"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HweLHQIHJi1"
      },
      "source": [
        "### Importing and preparing dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tqPhsNJyQ46"
      },
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4zrBUpM3zPL"
      },
      "source": [
        "!rm -rf sample_data"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W29darr8tVu",
        "outputId": "c61d9edf-8c95-4887-967e-eea8aad88231"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFd2nRiX-Pim"
      },
      "source": [
        "datapath = '/content/gdrive/MyDrive/data/'"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xZnYEiEx-8Z"
      },
      "source": [
        "from tensorflow_docs.vis import embed\n",
        "from tensorflow import keras\n",
        "from imutils import paths\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2MhdKMvyzid"
      },
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "\n",
        "MAX_SEQ_LENGTH = 20\n",
        "NUM_FEATURES = 2048"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqdykdjvzIZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53d408a5-1573-448c-c474-d7a4e2c73de1"
      },
      "source": [
        "# open the file which have names of training videos\n",
        "from os import listdir\n",
        "from os.path import isfile,join\n",
        "\n",
        "bc = [f for f in listdir(f\"{datapath}goodtrain\") if isfile(join(f\"{datapath}goodtrain\",f))]\n",
        "sp = [f for f in listdir(f\"{datapath}ShoulderPressGoodTrain\") if isfile(join(f\"{datapath}ShoulderPressGoodTrain\",f))]\n",
        "allvideos = bc+sp\n",
        "\n",
        "videoclass = ['bicep_curl' for _ in range(len(bc))] + ['shoulder_press' for _ in range(len(sp))]\n",
        "\n",
        "# creating a dataframe having video names\n",
        "train = pd.DataFrame({'video_name':allvideos})\n",
        "train['class'] = videoclass\n",
        "\n",
        "print(train)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           video_name           class\n",
            "0        Good PY2.mp4      bicep_curl\n",
            "1       ry_good_9.MOV      bicep_curl\n",
            "2        Good PY5.mp4      bicep_curl\n",
            "3       ry_good_1.MOV      bicep_curl\n",
            "4        Good PY1.mp4      bicep_curl\n",
            "..                ...             ...\n",
            "81  SPDiffAngPY13.mp4  shoulder_press\n",
            "82       IMG_8661.MOV  shoulder_press\n",
            "83   SPDiffAngPY3.mp4  shoulder_press\n",
            "84   SPDiffAngPY2.mp4  shoulder_press\n",
            "85  SPDiffAngPY17.mp4  shoulder_press\n",
            "\n",
            "[86 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLbJi1t7zyCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2674e978-5bde-477a-dd2e-541f20006ec5"
      },
      "source": [
        "# open the .txt file which have names of test videos\n",
        "from os import listdir\n",
        "from os.path import isfile,join\n",
        "\n",
        "bctest = [f for f in listdir(f\"{datapath}goodtest\") if isfile(join(f\"{datapath}goodtest\",f))]\n",
        "sptest = [f for f in listdir(f\"{datapath}ShoulderPressGoodTest\") if isfile(join(f\"{datapath}ShoulderPressGoodTest\",f))]\n",
        "alltest = bctest+sptest\n",
        "\n",
        "testclass = ['bicep_curl' for _ in range(len(bctest))] + ['shoulder_press' for _ in range(len(sptest))]\n",
        "\n",
        "# creating a dataframe having video names\n",
        "test = pd.DataFrame({'video_name':alltest})\n",
        "test['class'] = testclass\n",
        "\n",
        "print(test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       video_name           class\n",
            "0      Good 3.mp3      bicep_curl\n",
            "1      Good 6.mov      bicep_curl\n",
            "2      Good 1.mov      bicep_curl\n",
            "3      Good 8.mov      bicep_curl\n",
            "4     Good 10.mov      bicep_curl\n",
            "5     Good 12.mov      bicep_curl\n",
            "6     Good 11.mov      bicep_curl\n",
            "7     Good 13.mov      bicep_curl\n",
            "8      Good 4.mov      bicep_curl\n",
            "9      Good 2.mov      bicep_curl\n",
            "10     Good 9.mov      bicep_curl\n",
            "11     Good 7.mov      bicep_curl\n",
            "12     Good 3.mov      bicep_curl\n",
            "13  SP good 3.mov  shoulder_press\n",
            "14  SP good 1.mov  shoulder_press\n",
            "15  SP good 2.mov  shoulder_press\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsDGz1MEG4jA"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usHh8hWc0Rml"
      },
      "source": [
        "def load_video(path, i, max_frames=0):\n",
        "    if path == \"train\":\n",
        "        videoname = train['video_name'][i]\n",
        "        videoclass = train['class'][i]\n",
        "        if videoclass == \"bicep_curl\":\n",
        "          videotype = \"goodT\"\n",
        "        elif videoclass == \"shoulder_press\":\n",
        "          videotype = \"ShoulderPressGoodT\"\n",
        "        video = datapath+videotype+\"rain/\"+videoname\n",
        "\n",
        "    elif path == \"test\":\n",
        "        videoname = test['video_name'][i]\n",
        "        videoclass = test['class'][i]\n",
        "        if videoclass == \"bicep_curl\":\n",
        "          videotype = \"goodT\"\n",
        "        elif videoclass == \"shoulder_press\":\n",
        "          videotype = \"ShoulderPressGoodT\"\n",
        "        video = datapath+videotype+\"est/\"+videoname\n",
        "    cap = cv2.VideoCapture(video)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frameID = cap.get(1)\n",
        "            if (frameID%2==0):\n",
        "                frame = cv2.resize(frame, (224, 224))\n",
        "                frames.append(frame)\n",
        "            # storing the frames in a new folder named train_1\n",
        "            # filename = f\"{path}_1/{train['video_name'][i]}_frame{frameID/2}_{train['class'][i]}.jpg\"\n",
        "            # cv2.imwrite(filename, frame)\n",
        "            # if len(frames) == max_frames:\n",
        "            #     break\n",
        "    finally:\n",
        "        cap.release()\n",
        "    return np.array(frames)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV2uWmkk1sUp"
      },
      "source": [
        "def build_feature_extractor():\n",
        "    feature_extractor = keras.applications.InceptionV3(\n",
        "        weights=\"imagenet\",\n",
        "        include_top=False,\n",
        "        pooling=\"avg\",\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    )\n",
        "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
        "\n",
        "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "    preprocessed = preprocess_input(inputs)\n",
        "\n",
        "    outputs = feature_extractor(preprocessed)\n",
        "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
        "\n",
        "\n",
        "feature_extractor = build_feature_extractor()\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX8q_AsV2xMh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf5d3931-0d04-4c26-f576-600c5f1936e9"
      },
      "source": [
        "label_processor = keras.layers.StringLookup(\n",
        "    num_oov_indices=0, vocabulary=np.unique(train['class'])\n",
        ")\n",
        "print(label_processor.get_vocabulary())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bicep_curl', 'shoulder_press']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEMYf5rK3QDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f09e4fc2-bc62-4cae-da88-ccd87bc19570"
      },
      "source": [
        "def prepare_all_videos(df, root_dir):\n",
        "    num_samples = len(df)\n",
        "    video_paths = df[\"video_name\"].values.tolist()\n",
        "    labels = df[\"class\"].values\n",
        "    labels = label_processor(labels[..., None]).numpy()\n",
        "\n",
        "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
        "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
        "    # masked with padding or not.\n",
        "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
        "    frame_features = np.zeros(\n",
        "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
        "    )\n",
        "\n",
        "    # For each video.\n",
        "    for idx, path in enumerate(video_paths):\n",
        "        # Gather all its frames and add a batch dimension.\n",
        "        # print(os.path.join(datapath, \"bad\"+ root_dir, path))\n",
        "        frames = load_video(root_dir, idx)\n",
        "        # frames2 = load_video(os.path.join(datapath, \"bad\"+root_dir, path), idx)\n",
        "        frames = frames[None, ...]\n",
        "        # print(frames)\n",
        "\n",
        "        # Initialize placeholders to store the masks and features of the current video.\n",
        "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "        temp_frame_features = np.zeros(\n",
        "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
        "        )\n",
        "\n",
        "        # Extract features from the frames of the current video.\n",
        "        for i, batch in enumerate(frames):\n",
        "            video_length = batch.shape[0]\n",
        "            length = min(MAX_SEQ_LENGTH, video_length)\n",
        "            for j in range(length):\n",
        "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
        "                    batch[None, j, :]\n",
        "                )\n",
        "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
        "\n",
        "        frame_features[idx,] = temp_frame_features.squeeze()\n",
        "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
        "\n",
        "    return (frame_features, frame_masks), labels\n",
        "\n",
        "\n",
        "train_data, train_labels = prepare_all_videos(train, \"train\")\n",
        "test_data, test_labels = prepare_all_videos(test, \"test\")\n",
        "\n",
        "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
        "print(f\"Frame masks in train set: {train_data[1].shape}\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frame features in train set: (86, 20, 2048)\n",
            "Frame masks in train set: (86, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G38AYHXLCvEZ",
        "outputId": "02710bc4-1acf-42ee-dcda-89a62b9d2624"
      },
      "source": [
        "# Utility for our sequence model.\n",
        "def get_sequence_model():\n",
        "    class_vocab = label_processor.get_vocabulary()\n",
        "\n",
        "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
        "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "\n",
        "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
        "    # https://keras.io/api/layers/recurrent_layers/gru/\n",
        "    x = keras.layers.GRU(16, return_sequences=True)(\n",
        "        frame_features_input, mask=mask_input\n",
        "    )\n",
        "    x = keras.layers.GRU(8)(x)\n",
        "    x = keras.layers.Dropout(0.4)(x)\n",
        "    x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
        "    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n",
        "\n",
        "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
        "\n",
        "    rnn_model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return rnn_model\n",
        "\n",
        "\n",
        "# Utility for running experiments.\n",
        "def run_experiment():\n",
        "    filepath = \"/tmp/video_classifier\"\n",
        "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
        "    )\n",
        "\n",
        "    seq_model = get_sequence_model()\n",
        "    history = seq_model.fit(\n",
        "        [train_data[0], train_data[1]],\n",
        "        train_labels,\n",
        "        validation_split=0.3,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=[checkpoint],\n",
        "    )\n",
        "\n",
        "    seq_model.load_weights(filepath)\n",
        "    _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history, seq_model\n",
        "\n",
        "\n",
        "_, sequence_model = run_experiment()\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/2 [==============>...............] - ETA: 7s - loss: 0.7272 - accuracy: 0.5625\n",
            "Epoch 00001: val_loss improved from inf to 0.70219, saving model to /tmp/video_classifier\n",
            "2/2 [==============================] - 10s 3s/step - loss: 0.7120 - accuracy: 0.3333 - val_loss: 0.7022 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6938 - accuracy: 0.1250\n",
            "Epoch 00002: val_loss improved from 0.70219 to 0.69267, saving model to /tmp/video_classifier\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.6925 - accuracy: 0.4500 - val_loss: 0.6927 - val_accuracy: 0.6154\n",
            "Epoch 3/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6946 - accuracy: 0.7188\n",
            "Epoch 00003: val_loss improved from 0.69267 to 0.67632, saving model to /tmp/video_classifier\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.7051 - accuracy: 0.7500 - val_loss: 0.6763 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6875 - accuracy: 0.7812\n",
            "Epoch 00004: val_loss improved from 0.67632 to 0.66305, saving model to /tmp/video_classifier\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.6900 - accuracy: 0.8000 - val_loss: 0.6631 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7001 - accuracy: 0.7188\n",
            "Epoch 00005: val_loss improved from 0.66305 to 0.65779, saving model to /tmp/video_classifier\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 0.6956 - accuracy: 0.7667 - val_loss: 0.6578 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6881 - accuracy: 0.8438\n",
            "Epoch 00006: val_loss improved from 0.65779 to 0.65334, saving model to /tmp/video_classifier\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.6882 - accuracy: 0.8167 - val_loss: 0.6533 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6876 - accuracy: 0.8125\n",
            "Epoch 00007: val_loss improved from 0.65334 to 0.64955, saving model to /tmp/video_classifier\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.6820 - accuracy: 0.8167 - val_loss: 0.6495 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.6854 - accuracy: 0.9333\n",
            "Epoch 00008: val_loss improved from 0.64955 to 0.64488, saving model to /tmp/video_classifier\n",
            "2/2 [==============================] - 0s 107ms/step - loss: 0.6854 - accuracy: 0.9333 - val_loss: 0.6449 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.6703 - accuracy: 0.9333\n",
            "Epoch 00009: val_loss improved from 0.64488 to 0.64044, saving model to /tmp/video_classifier\n",
            "2/2 [==============================] - 0s 105ms/step - loss: 0.6703 - accuracy: 0.9333 - val_loss: 0.6404 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6727 - accuracy: 0.9062\n",
            "Epoch 00010: val_loss improved from 0.64044 to 0.63623, saving model to /tmp/video_classifier\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 0.6739 - accuracy: 0.9000 - val_loss: 0.6362 - val_accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6757 - accuracy: 0.9375\n",
            "Test accuracy: 93.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRtOZsM7Gkg7"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQKmKOkxPSXs",
        "outputId": "3e3ddb73-b5b1-442a-d90d-95d92ed3d4ec"
      },
      "source": [
        "def prepare_single_video(frames):\n",
        "    frames = frames[None, ...]\n",
        "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
        "\n",
        "    for i, batch in enumerate(frames):\n",
        "        video_length = batch.shape[0]\n",
        "        length = min(MAX_SEQ_LENGTH, video_length)\n",
        "        for j in range(length):\n",
        "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
        "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
        "\n",
        "    return frame_features, frame_mask\n",
        "\n",
        "\n",
        "def sequence_prediction(i,video):\n",
        "    predicted_label = None\n",
        "    predicted_prob = 0\n",
        "    class_vocab = label_processor.get_vocabulary()\n",
        "\n",
        "    frames = load_video(\"test\", i)\n",
        "    frame_features, frame_mask = prepare_single_video(frames)\n",
        "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
        "\n",
        "    for i in np.argsort(probabilities)[::-1]:\n",
        "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
        "        if probabilities[i] > predicted_prob:\n",
        "          predicted_prob = probabilities[i]\n",
        "          predicted_label = class_vocab[i]\n",
        "    \n",
        "    return frames,video,predicted_prob,predicted_label\n",
        "\n",
        "\n",
        "for idx, video in enumerate(test[\"video_name\"].values.tolist()):\n",
        "    print(f\"Test video path: {video}\")\n",
        "    test_frames,_,_,_ = sequence_prediction(idx,video)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test video path: Good 3.mp3\n",
            "  bicep_curl: 50.69%\n",
            "  shoulder_press: 49.31%\n",
            "bicep_curl\n",
            "Test video path: Good 6.mov\n",
            "  bicep_curl: 50.69%\n",
            "  shoulder_press: 49.31%\n",
            "bicep_curl\n",
            "Test video path: Good 1.mov\n",
            "  bicep_curl: 50.69%\n",
            "  shoulder_press: 49.31%\n",
            "bicep_curl\n",
            "Test video path: Good 8.mov\n",
            "  bicep_curl: 50.69%\n",
            "  shoulder_press: 49.31%\n",
            "bicep_curl\n",
            "Test video path: Good 10.mov\n",
            "  bicep_curl: 50.69%\n",
            "  shoulder_press: 49.31%\n",
            "bicep_curl\n",
            "Test video path: Good 12.mov\n",
            "  bicep_curl: 50.69%\n",
            "  shoulder_press: 49.31%\n",
            "bicep_curl\n",
            "Test video path: Good 11.mov\n",
            "  bicep_curl: 50.69%\n",
            "  shoulder_press: 49.31%\n",
            "bicep_curl\n",
            "Test video path: Good 13.mov\n",
            "  bicep_curl: 50.69%\n",
            "  shoulder_press: 49.31%\n",
            "bicep_curl\n",
            "Test video path: Good 4.mov\n",
            "  bicep_curl: 50.69%\n",
            "  shoulder_press: 49.31%\n",
            "bicep_curl\n",
            "Test video path: Good 2.mov\n",
            "  bicep_curl: 50.69%\n",
            "  shoulder_press: 49.31%\n",
            "bicep_curl\n",
            "Test video path: Good 9.mov\n",
            "  bicep_curl: 50.69%\n",
            "  shoulder_press: 49.31%\n",
            "bicep_curl\n",
            "Test video path: Good 7.mov\n",
            "  bicep_curl: 50.69%\n",
            "  shoulder_press: 49.31%\n",
            "bicep_curl\n",
            "Test video path: Good 3.mov\n",
            "  bicep_curl: 50.69%\n",
            "  shoulder_press: 49.31%\n",
            "bicep_curl\n",
            "Test video path: SP good 3.mov\n",
            "  shoulder_press: 52.94%\n",
            "  bicep_curl: 47.06%\n",
            "shoulder_press\n",
            "Test video path: SP good 1.mov\n",
            "  shoulder_press: 52.90%\n",
            "  bicep_curl: 47.10%\n",
            "shoulder_press\n",
            "Test video path: SP good 2.mov\n",
            "  bicep_curl: 50.69%\n",
            "  shoulder_press: 49.31%\n",
            "bicep_curl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpdsvzUEnGee"
      },
      "source": [
        ""
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFAn4z6JnG6P"
      },
      "source": [
        "## Adding Pengyu's classifier here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_put52pvE9zI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d11aaf98-9186-46e7-fd16-41efd530e273"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as numpy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "train_data = pd.read_csv('mean_variance.csv') # Load training data\n",
        "test_data = pd.read_csv('mean_variance_test.csv') # Load test data\n",
        "all_data = pd.concat([train_data,test_data])\n",
        "print(all_data)\n",
        "\n",
        "\n",
        "\n",
        "##normalise data / scaling / standard scaling "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   file  r_arm_mean  ...  l_hip_variance  class\n",
            "0   20211024_221837.mp4  145.936091  ...        6.381162      0\n",
            "1   20211024_221843.mp4  146.998889  ...       36.845617      0\n",
            "2   20211024_221849.mp4  132.311392  ...        6.705885      0\n",
            "3   20211024_221854.mp4  129.495333  ...        3.407046      0\n",
            "4   20211024_221859.mp4  144.987807  ...       27.398339      0\n",
            "..                  ...         ...  ...             ...    ...\n",
            "20           Good 4.mov   89.245071  ...      534.946483      1\n",
            "21           Good 6.mov  233.412435  ...        7.091592      1\n",
            "22           Good 7.mov  256.786654  ...        5.797683      1\n",
            "23           Good 8.mov  245.501719  ...       92.369416      1\n",
            "24           Good 9.mov  108.855380  ...      544.512392      1\n",
            "\n",
            "[98 rows x 14 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWTPSxnFnOW-",
        "outputId": "56b4c116-b4d3-4937-d5b1-d6a7583b046f"
      },
      "source": [
        "# Use \n",
        "\n",
        "# Split into training data for X_train,X_test,y_train,y_test\n",
        "# X_train = train_data.drop(['file','class'],1)\n",
        "# y_train = train_data['class']\n",
        "\n",
        "# X_test = test_data.drop(['file','class'],1)\n",
        "# y_test = test_data['class']\n",
        "\n",
        "# use train_test_split\n",
        "#X_train,X_test,y_train,y_test = train_test_split(train_data.drop(['file','class'],1),train_data['class'],shuffle=True,test_size=0.1)\n",
        "#print(X_train,X_test,y_train,y_test)\n",
        "\n",
        "# Use \n",
        "\n",
        "# Split into training data for X_train,X_test,y_train,y_test\n",
        "X_train = train_data.drop(['file','class'],1)\n",
        "y_train = train_data['class']\n",
        "\n",
        "X_test = test_data.drop(['file','class'],1)\n",
        "y_test = test_data['class']\n",
        "\n",
        "\n",
        "print (X_train)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler() \n",
        "X_train= scaler.fit_transform(X_train)\n",
        "X_test= scaler.transform(X_test)\n",
        "print (X_train)\n",
        "\n",
        "# from sklearn import preprocessing\n",
        "\n",
        "# X_train = preprocessing.normalize(X_train)\n",
        "# X_test =  preprocessing.normalize(X_test)\n",
        "\n",
        "# print (X_train)\n",
        "\n",
        "\n",
        "\n",
        "# use train_test_split\n",
        "# X_train,X_test,y_train,y_test = train_test_split(train_data.drop(['file','class'],1),train_data['class'],shuffle=True,test_size=0.1)\n",
        "# print(X_train,X_test,y_train,y_test)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    r_arm_mean  r_arm_variance  ...  l_hip_mean  l_hip_variance\n",
            "0   145.936091     1354.582741  ...  184.728636        6.381162\n",
            "1   146.998889     1328.783288  ...  182.833810       36.845617\n",
            "2   132.311392     1895.172804  ...  185.649747        6.705885\n",
            "3   129.495333     2273.788320  ...  186.610533        3.407046\n",
            "4   144.987807     1630.757389  ...  184.429298       27.398339\n",
            "..         ...             ...  ...         ...             ...\n",
            "68  224.989574     2237.189756  ...  165.840638       13.307019\n",
            "69  233.788065     2531.207639  ...  167.938387       12.832817\n",
            "70  110.878600     2225.233718  ...  176.655600        5.547552\n",
            "71  109.989400     1871.953757  ...  177.027200        2.853641\n",
            "72  111.800870     2737.795141  ...  176.936957        3.796777\n",
            "\n",
            "[73 rows x 12 columns]\n",
            "[[4.22586179e-01 2.63201087e-01 3.69554427e-01 4.06896689e-01\n",
            "  5.27517442e-01 8.69809027e-01 3.96987449e-02 1.09515289e-01\n",
            "  4.63982346e-01 7.12646604e-03 8.22379053e-01 6.35094644e-03]\n",
            " [4.28376568e-01 2.56219524e-01 3.72021947e-01 3.80229551e-01\n",
            "  4.88878011e-01 8.72047043e-01 2.17831026e-01 6.48206649e-01\n",
            "  3.49373151e-01 2.37692298e-02 7.42300317e-01 3.84676531e-02]\n",
            " [3.48355413e-01 4.09489589e-01 3.02404330e-01 5.93417192e-01\n",
            "  5.07805094e-01 9.59739454e-01 1.36647167e-01 4.91892881e-01\n",
            "  5.17356289e-01 4.07451737e-03 8.61306811e-01 6.69328008e-03]\n",
            " [3.33012819e-01 5.11946331e-01 2.77622100e-01 7.12939213e-01\n",
            "  4.62558148e-01 8.78322278e-01 2.35908026e-01 6.81735249e-01\n",
            "  5.88018548e-01 3.57140845e-03 9.01911349e-01 3.21552737e-03]\n",
            " [4.17419691e-01 3.37936415e-01 3.43222241e-01 4.49280396e-01\n",
            "  5.85372328e-01 7.74600363e-01 4.19873026e-01 8.85259483e-01\n",
            "  4.43955547e-01 1.87893970e-02 8.09728494e-01 2.85079983e-02]\n",
            " [3.30670392e-01 2.97692315e-01 2.83117904e-01 4.75810145e-01\n",
            "  2.50038645e-01 7.31107485e-01 7.58850102e-01 7.43538965e-01\n",
            "  2.83693767e-01 2.31694888e-02 4.86596484e-01 1.40650255e-02]\n",
            " [3.83963893e-01 3.65736002e-01 3.20582001e-01 4.49213931e-01\n",
            "  1.13778437e-02 2.47361501e-03 6.42140617e-01 8.98536225e-01\n",
            "  4.43337128e-01 1.16891054e-02 5.14377383e-01 4.51485818e-02]\n",
            " [4.51541786e-01 1.61279920e-01 4.03755603e-01 1.56680111e-01\n",
            "  3.41452499e-01 8.77686427e-01 1.00000000e+00 4.82751690e-05\n",
            "  4.14731671e-01 1.78688005e-03 4.05944668e-01 2.06300559e-02]\n",
            " [4.37018941e-01 2.59703191e-01 3.92237330e-01 1.77018119e-01\n",
            "  3.07942362e-01 7.97875522e-01 9.99270020e-01 5.56151937e-04\n",
            "  4.11885079e-01 7.17435946e-04 3.60733382e-01 2.05184824e-02]\n",
            " [4.62581906e-01 1.17824972e-01 3.97309987e-01 1.52983683e-01\n",
            "  0.00000000e+00 1.79915764e-05 8.28116804e-01 5.99915888e-01\n",
            "  3.87974176e-01 1.35430516e-03 3.31625043e-01 1.61083678e-02]\n",
            " [8.44067057e-01 6.03970055e-01 8.06366055e-01 9.36804918e-01\n",
            "  8.39601167e-01 5.13966810e-01 9.69568233e-01 3.09958150e-02\n",
            "  7.09161634e-01 2.73993047e-02 6.18780117e-01 1.50252581e-02]\n",
            " [7.66368919e-01 3.42338560e-01 7.44126374e-01 4.53545268e-01\n",
            "  7.83606287e-01 6.71138607e-01 9.82984134e-01 3.57095608e-02\n",
            "  7.31435298e-01 2.37363541e-02 6.35183382e-01 7.60512742e-03]\n",
            " [8.98895263e-01 2.92473665e-01 9.17068786e-01 2.60250307e-01\n",
            "  7.97419711e-01 6.75215604e-01 3.69791614e-01 9.41226972e-01\n",
            "  6.16108994e-01 1.24753144e-02 4.96094022e-01 0.00000000e+00]\n",
            " [7.92710933e-01 4.43606911e-01 7.95449889e-01 7.10843144e-01\n",
            "  6.62783659e-01 8.66548525e-01 6.58295660e-01 8.66484182e-01\n",
            "  6.68332898e-01 1.82269734e-02 6.13600517e-01 9.95456279e-03]\n",
            " [8.24056427e-01 5.23294535e-01 8.03847472e-01 8.65869659e-01\n",
            "  5.43441617e-01 9.52195779e-01 3.22565340e-01 8.29302989e-01\n",
            "  4.63451758e-01 3.13123579e-02 5.30840453e-01 2.19763184e-02]\n",
            " [8.06075395e-01 3.15138668e-01 8.39542617e-01 6.05827860e-01\n",
            "  4.39749903e-01 9.64872860e-01 7.57082011e-01 6.61420513e-01\n",
            "  9.15976426e-01 1.04002222e-01 9.97029692e-01 8.56606142e-02]\n",
            " [2.69580099e-01 7.11098906e-01 2.56341648e-01 7.24106594e-01\n",
            "  9.83416666e-01 2.56547059e-03 9.28426001e-01 1.87200325e-01\n",
            "  4.99897928e-01 7.10191471e-03 8.40435862e-01 7.96418381e-03]\n",
            " [3.01945287e-01 2.47032206e-01 2.31434101e-01 4.16112258e-01\n",
            "  4.86017559e-01 6.98956833e-01 5.46756277e-01 7.39872214e-01\n",
            "  6.62461819e-01 1.14986060e-02 9.36671851e-01 7.85564855e-02]\n",
            " [1.64658888e-01 2.86194905e-01 8.44680704e-02 4.40934517e-01\n",
            "  3.89451264e-01 7.25470905e-01 4.24643516e-01 8.28836183e-01\n",
            "  7.90251172e-01 5.05313431e-02 9.58439958e-01 1.09857241e-01]\n",
            " [3.00339370e-01 2.95303181e-01 2.43412644e-01 3.12282628e-01\n",
            "  4.80342779e-01 6.31756421e-01 3.98996565e-01 6.91575003e-01\n",
            "  3.34056562e-01 4.17332087e-03 8.31993296e-01 7.73758765e-03]\n",
            " [4.29525348e-01 3.76872024e-01 3.46368460e-01 4.02522886e-01\n",
            "  7.35887666e-01 7.18554841e-01 4.63276951e-01 9.83380390e-01\n",
            "  6.01258538e-01 5.72645961e-03 9.14580974e-01 5.34293769e-02]\n",
            " [3.47222082e-01 6.27208588e-01 4.43854436e-01 0.00000000e+00\n",
            "  9.31872677e-01 5.56279248e-02 9.75370055e-01 2.15335281e-03\n",
            "  6.19557641e-01 6.13616437e-03 8.66214593e-01 7.98267214e-03]\n",
            " [2.41021995e-01 1.00000000e+00 3.34731709e-01 8.31101244e-02\n",
            "  8.90915498e-01 8.66482416e-02 9.22482558e-01 3.98966733e-02\n",
            "  4.32040282e-01 4.86005812e-03 8.06544800e-01 1.91369065e-03]\n",
            " [3.22773549e-01 2.47029597e-01 4.03835380e-01 1.48337818e-02\n",
            "  8.97022870e-01 4.31106749e-02 9.35819368e-01 1.01259788e-02\n",
            "  3.25249640e-01 7.03260482e-03 7.01056431e-01 6.62650580e-03]\n",
            " [2.59993042e-01 6.51660552e-01 1.76579895e-01 8.29145735e-01\n",
            "  5.22853491e-01 7.78692632e-01 4.09799848e-01 8.23336124e-01\n",
            "  6.12609864e-01 8.54321024e-03 8.60006312e-01 1.18110515e-01]\n",
            " [3.36650785e-01 0.00000000e+00 2.50299651e-01 1.40098069e-01\n",
            "  4.56715926e-01 6.30580767e-01 5.13491796e-01 6.61249074e-01\n",
            "  8.75895400e-01 6.60231653e-02 9.85383071e-01 3.50935970e-01]\n",
            " [3.36650785e-01 0.00000000e+00 2.50299651e-01 1.40098069e-01\n",
            "  4.56715926e-01 6.30580767e-01 5.13491796e-01 6.61249074e-01\n",
            "  8.75895400e-01 6.60231653e-02 9.85383071e-01 3.50935970e-01]\n",
            " [3.61044473e-01 1.52790330e-01 3.26138709e-01 2.24394411e-01\n",
            "  9.91879329e-01 3.23156546e-04 6.97153265e-02 2.35269446e-01\n",
            "  9.18316758e-01 1.16361268e-02 3.84156254e-01 1.02097907e-01]\n",
            " [7.75253152e-01 8.96609987e-02 7.90583512e-01 1.65116159e-01\n",
            "  9.89756563e-01 4.72318419e-04 3.45561915e-02 5.25357940e-05\n",
            "  6.95633057e-01 4.83580161e-03 2.66380154e-01 1.34120013e-02]\n",
            " [8.60961302e-01 3.95164417e-01 8.50818480e-01 7.21919469e-01\n",
            "  9.69425373e-01 2.27321922e-03 5.70970261e-01 9.12843186e-01\n",
            "  6.57107583e-01 1.28697239e-02 1.07213857e-01 2.21008108e-02]\n",
            " [3.11379798e-01 2.95861085e-01 2.82433626e-01 2.67669919e-01\n",
            "  9.92057934e-01 1.01045887e-04 0.00000000e+00 1.93884126e-04\n",
            "  1.00000000e+00 9.64644876e-04 4.65901024e-01 4.63971114e-03]\n",
            " [2.89297177e-01 2.31241551e-01 2.46040977e-01 3.08889925e-01\n",
            "  9.98048282e-01 1.26773679e-04 1.51361500e-02 4.06024236e-04\n",
            "  7.57752392e-01 1.19921619e-01 4.06442703e-01 5.72706826e-02]\n",
            " [3.30243938e-01 2.60044982e-01 2.92576437e-01 2.81365379e-01\n",
            "  9.96490574e-01 4.58982817e-04 1.84180962e-02 8.57141044e-04\n",
            "  9.07813146e-01 1.37208785e-01 4.49243765e-01 1.63988963e-01]\n",
            " [0.00000000e+00 1.82291876e-01 8.56094180e-02 2.04070097e-01\n",
            "  9.73307474e-01 1.89528890e-04 1.31375181e-02 5.51867498e-04\n",
            "  9.71270351e-01 1.88853736e-03 3.97458509e-01 9.23610674e-03]\n",
            " [9.62001176e-01 5.87602594e-01 9.75971888e-01 1.00000000e+00\n",
            "  9.59156267e-01 2.40761488e-03 5.23728540e-01 9.55451694e-01\n",
            "  6.85130367e-01 7.70246079e-03 1.32142071e-01 1.53183375e-02]\n",
            " [8.13968683e-01 1.48522794e-01 7.91533928e-01 1.86126589e-01\n",
            "  9.88564304e-01 9.75587496e-04 3.16746350e-02 8.85124804e-05\n",
            "  6.29369934e-01 9.91861018e-03 1.39694326e-01 2.51652105e-02]\n",
            " [8.34000039e-01 1.44226805e-01 8.01637964e-01 1.76134664e-01\n",
            "  9.88506886e-01 4.16177005e-04 2.36859036e-02 0.00000000e+00\n",
            "  6.20567678e-01 1.27269790e-02 1.74271646e-01 2.16239248e-02]\n",
            " [3.41251930e-01 4.51861164e-01 3.18720114e-01 7.30897942e-01\n",
            "  5.50036030e-01 9.56970851e-01 1.17928404e-01 4.37937446e-01\n",
            "  3.68453679e-01 1.00000000e+00 7.15231111e-01 1.00000000e+00]\n",
            " [3.77512547e-01 3.50170069e-01 3.50112026e-01 5.07473590e-01\n",
            "  6.39942639e-01 9.09832498e-01 3.12778732e-01 8.86016929e-01\n",
            "  5.37307897e-01 1.68791380e-03 8.31086564e-01 2.35542114e-03]\n",
            " [3.89094180e-01 4.17015962e-01 3.53084295e-01 5.62627423e-01\n",
            "  6.58379299e-01 8.89064839e-01 1.23915032e-01 4.67084921e-01\n",
            "  4.90089877e-01 2.37312039e-03 8.33244739e-01 4.23674012e-03]\n",
            " [3.80828165e-01 3.89866262e-01 3.54778280e-01 5.05296389e-01\n",
            "  4.42071108e-01 9.86512897e-01 1.81356642e-01 6.18072193e-01\n",
            "  3.79610358e-01 4.86787541e-03 7.67248640e-01 4.41802728e-03]\n",
            " [3.95823879e-01 3.08219327e-01 3.98956605e-01 3.46378220e-01\n",
            "  4.83231119e-01 1.00000000e+00 1.63121108e-01 5.62875786e-01\n",
            "  4.09643502e-01 4.64785060e-03 8.08306551e-01 3.60344180e-03]\n",
            " [3.70027864e-01 3.74084017e-01 3.03654116e-01 5.17954283e-01\n",
            "  4.72213505e-04 5.26753101e-05 4.00846037e-01 9.90766059e-01\n",
            "  6.64137813e-01 7.71101960e-04 6.66750526e-01 4.99315030e-03]\n",
            " [3.53852806e-01 3.81329881e-01 2.86696132e-01 5.39832528e-01\n",
            "  6.05670704e-03 7.06632057e-05 5.79015153e-01 9.98528697e-01\n",
            "  5.96194159e-01 4.52464818e-04 6.27226517e-01 3.79930180e-03]\n",
            " [4.01424116e-01 3.27067418e-01 3.36791914e-01 4.31174773e-01\n",
            "  3.70680100e-03 3.58094441e-05 7.27939035e-01 8.18938502e-01\n",
            "  6.50375385e-01 0.00000000e+00 6.01101592e-01 9.30402155e-03]\n",
            " [3.85458830e-01 4.00446525e-01 3.09703073e-01 4.76267524e-01\n",
            "  5.99974527e-03 6.56301122e-05 8.05155953e-01 6.41659035e-01\n",
            "  5.78273338e-01 1.49557381e-04 5.41891528e-01 6.75045597e-03]\n",
            " [3.64472648e-01 4.14059530e-01 3.02519058e-01 4.99688881e-01\n",
            "  1.76859576e-03 0.00000000e+00 8.11718456e-01 6.37108669e-01\n",
            "  5.59970234e-01 6.71260451e-06 5.35940655e-01 4.64795387e-03]\n",
            " [8.17873153e-01 4.84553094e-01 7.96791097e-01 7.10267470e-01\n",
            "  8.51056945e-01 5.06581522e-01 9.85738251e-01 2.60835126e-04\n",
            "  6.85130437e-01 1.01754572e-02 6.00988444e-01 3.05500300e-03]\n",
            " [8.29127112e-01 4.52951860e-01 8.22755018e-01 6.43318420e-01\n",
            "  9.66878608e-01 1.51742602e-01 9.87756790e-01 1.36088706e-04\n",
            "  7.39837952e-01 1.60502249e-02 6.65027051e-01 6.13522095e-03]\n",
            " [2.74484810e-01 5.62707831e-01 2.10968260e-01 8.00804269e-01\n",
            "  3.18682613e-01 7.80428116e-01 4.83562675e-01 1.00000000e+00\n",
            "  5.98624075e-01 4.04225555e-03 8.51153555e-01 2.00542346e-02]\n",
            " [2.41221608e-01 5.60298576e-01 1.77707608e-01 8.26154211e-01\n",
            "  3.97876166e-01 7.77207538e-01 4.26056866e-01 9.05149634e-01\n",
            "  1.62386142e-01 2.77769227e-03 7.49131722e-01 8.03986860e-03]\n",
            " [1.58654467e-01 4.64062728e-01 7.27184558e-02 7.72910739e-01\n",
            "  2.40930357e-01 5.82755362e-01 3.86470157e-01 9.18009470e-01\n",
            "  2.02767792e-01 7.10986743e-03 7.40833431e-01 1.16126654e-01]\n",
            " [2.33337656e-01 4.73537407e-01 1.54728029e-01 6.74281123e-01\n",
            "  3.50479093e-01 8.06316870e-01 5.51846733e-01 9.67333797e-01\n",
            "  6.59164876e-01 1.04588769e-03 9.08472749e-01 2.67162145e-02]\n",
            " [2.55816343e-01 5.84121266e-01 1.87345946e-01 7.95046504e-01\n",
            "  5.37080668e-01 9.16352703e-01 6.38038546e-01 9.02986813e-01\n",
            "  7.30745934e-01 1.56074140e-03 9.11452357e-01 5.73242877e-02]\n",
            " [2.43588113e-01 5.47733668e-01 1.88535774e-01 7.63505549e-01\n",
            "  4.97433063e-01 9.59867273e-01 6.59493133e-01 9.04128878e-01\n",
            "  7.73957485e-01 4.22003050e-03 9.09073311e-01 5.55224820e-02]\n",
            " [2.50729397e-01 5.44822948e-01 1.93182949e-01 7.40774955e-01\n",
            "  5.86916535e-01 9.25554357e-01 7.12703937e-01 8.08878524e-01\n",
            "  8.19155388e-01 4.67195914e-03 9.80059303e-01 1.09732973e-02]\n",
            " [2.46579411e-01 5.66791645e-01 1.92930283e-01 7.62120747e-01\n",
            "  5.47812636e-01 9.42111581e-01 7.01902927e-01 8.23647106e-01\n",
            "  8.95323287e-01 6.32476856e-03 9.49939018e-01 2.18915937e-01]\n",
            " [2.38722065e-01 6.90596064e-01 1.89901416e-01 8.49656037e-01\n",
            "  6.59101393e-01 8.57659520e-01 7.00715814e-01 8.14027106e-01\n",
            "  8.57759937e-01 4.16606291e-03 1.00000000e+00 5.57459837e-02]\n",
            " [2.21601024e-01 6.11487702e-01 1.67819886e-01 8.15824447e-01\n",
            "  6.64238440e-01 8.54553453e-01 6.47528687e-01 8.98600795e-01\n",
            "  8.59658965e-01 2.03078923e-03 9.25737172e-01 9.13109854e-02]\n",
            " [2.01734929e-01 5.66128483e-01 1.33333701e-01 8.02275131e-01\n",
            "  3.29705606e-01 7.12975706e-01 4.04572789e-01 9.04408930e-01\n",
            "  2.49989932e-01 2.20133022e-03 7.02666072e-01 1.39980058e-01]\n",
            " [9.74261892e-02 6.58460761e-01 0.00000000e+00 9.55753870e-01\n",
            "  2.24721675e-02 5.86270083e-04 9.27307085e-03 1.30538767e-03\n",
            "  0.00000000e+00 1.38232546e-01 2.42310648e-01 5.91821319e-01]\n",
            " [3.07940816e-01 3.88799389e-01 2.28931389e-01 7.50337076e-01\n",
            "  2.75283307e-01 7.07685376e-01 4.14198378e-01 9.61860946e-01\n",
            "  5.02795043e-01 2.87757209e-03 7.64090869e-01 7.05258191e-03]\n",
            " [9.12112996e-01 4.56989678e-01 8.57407837e-01 4.97824066e-01\n",
            "  1.37815656e-01 4.90220828e-01 6.38949520e-01 8.96950026e-01\n",
            "  1.69531739e-03 2.81952371e-02 3.00290193e-01 6.69785388e-03]\n",
            " [1.00000000e+00 3.73273046e-01 1.00000000e+00 4.96946627e-01\n",
            "  9.85495071e-01 4.68589039e-04 1.17874820e-02 1.29866760e-04\n",
            "  5.39630184e-01 3.51841329e-03 1.38999552e-01 3.89467576e-04]\n",
            " [2.18609786e-01 3.91723597e-01 1.76250699e-01 4.12895864e-01\n",
            "  1.00000000e+00 1.05970624e-04 1.64511313e-02 3.93541977e-04\n",
            "  9.52872326e-01 2.94585598e-03 5.50211914e-01 2.56189135e-03]\n",
            " [8.81426026e-01 4.52633220e-01 8.60518085e-01 7.42434133e-01\n",
            "  9.85901696e-01 1.12877054e-03 6.42423592e-03 1.14863378e-04\n",
            "  5.99176762e-01 1.71230515e-02 1.45803106e-02 1.90922103e-02]\n",
            " [8.67939661e-01 4.75220390e-01 8.46323725e-01 7.15028463e-01\n",
            "  9.90296316e-01 1.36215658e-03 1.25005348e-02 5.50406328e-05\n",
            "  6.68134884e-01 5.44041447e-03 5.74123988e-02 1.99385296e-02]\n",
            " [9.02210128e-01 6.18291034e-01 8.81732147e-01 7.81449093e-01\n",
            "  9.81734919e-01 7.82168946e-04 1.75005578e-02 3.66563057e-04\n",
            "  7.23955086e-01 5.44915255e-03 0.00000000e+00 1.05382114e-02]\n",
            " [8.53289333e-01 5.02042433e-01 8.51295686e-01 6.64171486e-01\n",
            "  9.83425363e-01 5.69116597e-04 2.24811407e-02 9.10498687e-05\n",
            "  7.75514324e-01 7.32780154e-03 2.41388247e-02 1.36524298e-02]\n",
            " [9.01225708e-01 5.81606299e-01 8.72884498e-01 6.42107350e-01\n",
            "  9.83866398e-01 7.11295788e-04 1.14055239e-01 3.25672552e-01\n",
            "  8.40980339e-01 5.86011010e-03 1.12793402e-01 1.31525091e-02]\n",
            " [2.31584198e-01 4.98807022e-01 2.15137786e-01 5.68138890e-01\n",
            "  9.13143455e-01 2.58178045e-01 1.83312617e-02 1.36228014e-04\n",
            "  9.05286141e-01 6.91403334e-03 4.81198248e-01 5.47212457e-03]\n",
            " [2.26739614e-01 4.03206307e-01 2.05503125e-01 5.07952543e-01\n",
            "  9.32474904e-01 2.02119776e-01 2.07469160e-02 3.17394158e-04\n",
            "  9.39521527e-01 5.32443484e-03 4.96902721e-01 2.63210857e-03]\n",
            " [2.36608954e-01 6.37510724e-01 2.18101159e-01 5.74565065e-01\n",
            "  9.73645381e-01 7.77029528e-02 2.03833617e-02 6.85123318e-04\n",
            "  9.93319913e-01 8.87146914e-03 4.93088872e-01 3.62639615e-03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUt8AsYSnPTM"
      },
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler    \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "cLGBYTSmnQZV",
        "outputId": "63d4108e-61ec-453f-86a3-4cf2e43c013b"
      },
      "source": [
        "sns.countplot(x='class',data=train_data)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f70dd204c10>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0Y-8ZbvnRH0"
      },
      "source": [
        "# Define a scaler to normalize input\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 4\n",
        "LEARNING_RATE = 0.001"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLIXM5U7nRon"
      },
      "source": [
        "## train data\n",
        "class TrainData(Dataset):\n",
        "    \n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "\n",
        "\n",
        "train_data = TrainData(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
        "## test data    \n",
        "class TestData(Dataset):\n",
        "    \n",
        "    def __init__(self, X_data):\n",
        "        self.X_data = X_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "    \n",
        "\n",
        "test_data = TestData(torch.FloatTensor(X_test))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM5ooadinSja"
      },
      "source": [
        "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True,drop_last=True)\n",
        "test_loader = DataLoader(dataset=test_data, batch_size=1,drop_last=True)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OA0qdG5nTLH"
      },
      "source": [
        "class BinaryClassification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BinaryClassification, self).__init__()\n",
        "        # Number of input features is 12., 6 * 2 angles of \n",
        "        self.layer_1 = nn.Linear(12, 64) \n",
        "        self.layer_2 = nn.Linear(64, 32)\n",
        "        self.layer_out = nn.Linear(32, 1) \n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.1) # prevents overfit, play with this also, up to 0.5\n",
        "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(32) ##\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        x = self.relu(self.layer_1(inputs))\n",
        "        # x = self.batchnorm1(x) ## test this after seed\n",
        "        x = self.relu(self.layer_2(x))\n",
        "        # x = self.batchnorm2(x) ## test this after seed #small dataset\n",
        "        x = self.dropout(x)\n",
        "        x = self.layer_out(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Nyr89DhnT5i",
        "outputId": "b562d942-f3bc-49b0-f3ef-0ae8543d42e1"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwX8_tIGnUiL",
        "outputId": "6c5db865-f69e-40a1-ad1d-5be65f88b053"
      },
      "source": [
        "model = BinaryClassification()\n",
        "model.to(device)\n",
        "print(model)\n",
        "criterion = nn.BCEWithLogitsLoss() #\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BinaryClassification(\n",
            "  (layer_1): Linear(in_features=12, out_features=64, bias=True)\n",
            "  (layer_2): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (layer_out): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (batchnorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (batchnorm2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tm4TwEGnVN5"
      },
      "source": [
        "def binary_acc(y_pred, y_test):\n",
        "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
        "\n",
        "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
        "    acc = correct_results_sum/y_test.shape[0]\n",
        "    acc = torch.round(acc * 100)\n",
        "    \n",
        "    return acc"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4rYcHP5nVxU",
        "outputId": "3c633153-2835-41e2-ccfd-8debddd43a1e"
      },
      "source": [
        "model.train()\n",
        "for e in range(1, EPOCHS+1):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        y_pred = model(X_batch)\n",
        "        \n",
        "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
        "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "\n",
        "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001: | Loss: 0.69214 | Acc: 52.778\n",
            "Epoch 002: | Loss: 0.66635 | Acc: 65.278\n",
            "Epoch 003: | Loss: 0.65240 | Acc: 65.278\n",
            "Epoch 004: | Loss: 0.62743 | Acc: 79.167\n",
            "Epoch 005: | Loss: 0.60101 | Acc: 77.778\n",
            "Epoch 006: | Loss: 0.56349 | Acc: 77.778\n",
            "Epoch 007: | Loss: 0.52136 | Acc: 81.944\n",
            "Epoch 008: | Loss: 0.48437 | Acc: 84.722\n",
            "Epoch 009: | Loss: 0.46606 | Acc: 81.944\n",
            "Epoch 010: | Loss: 0.42657 | Acc: 80.556\n",
            "Epoch 011: | Loss: 0.39481 | Acc: 81.944\n",
            "Epoch 012: | Loss: 0.37469 | Acc: 83.333\n",
            "Epoch 013: | Loss: 0.35630 | Acc: 84.722\n",
            "Epoch 014: | Loss: 0.34278 | Acc: 86.111\n",
            "Epoch 015: | Loss: 0.32767 | Acc: 83.333\n",
            "Epoch 016: | Loss: 0.30391 | Acc: 88.889\n",
            "Epoch 017: | Loss: 0.30123 | Acc: 87.500\n",
            "Epoch 018: | Loss: 0.29221 | Acc: 87.500\n",
            "Epoch 019: | Loss: 0.27270 | Acc: 88.889\n",
            "Epoch 020: | Loss: 0.24361 | Acc: 90.278\n",
            "Epoch 021: | Loss: 0.25316 | Acc: 90.278\n",
            "Epoch 022: | Loss: 0.23533 | Acc: 91.667\n",
            "Epoch 023: | Loss: 0.22899 | Acc: 91.667\n",
            "Epoch 024: | Loss: 0.23652 | Acc: 90.278\n",
            "Epoch 025: | Loss: 0.22864 | Acc: 88.889\n",
            "Epoch 026: | Loss: 0.21314 | Acc: 91.667\n",
            "Epoch 027: | Loss: 0.22209 | Acc: 91.667\n",
            "Epoch 028: | Loss: 0.21409 | Acc: 90.278\n",
            "Epoch 029: | Loss: 0.19481 | Acc: 88.889\n",
            "Epoch 030: | Loss: 0.18824 | Acc: 90.278\n",
            "Epoch 031: | Loss: 0.17649 | Acc: 93.056\n",
            "Epoch 032: | Loss: 0.16914 | Acc: 91.667\n",
            "Epoch 033: | Loss: 0.15912 | Acc: 94.444\n",
            "Epoch 034: | Loss: 0.16439 | Acc: 90.278\n",
            "Epoch 035: | Loss: 0.15573 | Acc: 93.056\n",
            "Epoch 036: | Loss: 0.14938 | Acc: 91.667\n",
            "Epoch 037: | Loss: 0.13818 | Acc: 93.056\n",
            "Epoch 038: | Loss: 0.14073 | Acc: 93.056\n",
            "Epoch 039: | Loss: 0.13522 | Acc: 93.056\n",
            "Epoch 040: | Loss: 0.13408 | Acc: 94.444\n",
            "Epoch 041: | Loss: 0.12909 | Acc: 95.833\n",
            "Epoch 042: | Loss: 0.12540 | Acc: 94.444\n",
            "Epoch 043: | Loss: 0.09875 | Acc: 98.611\n",
            "Epoch 044: | Loss: 0.11944 | Acc: 97.222\n",
            "Epoch 045: | Loss: 0.10609 | Acc: 97.222\n",
            "Epoch 046: | Loss: 0.09967 | Acc: 98.611\n",
            "Epoch 047: | Loss: 0.09458 | Acc: 98.611\n",
            "Epoch 048: | Loss: 0.09699 | Acc: 98.611\n",
            "Epoch 049: | Loss: 0.09547 | Acc: 98.611\n",
            "Epoch 050: | Loss: 0.09300 | Acc: 97.222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZHSETPRnW6K",
        "outputId": "3daa0f4e-fa7f-429a-c777-f63e4f0c3048"
      },
      "source": [
        "y_pred_list = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for X_batch in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_test_pred = model(X_batch)\n",
        "        y_test_pred = torch.sigmoid(y_test_pred) ##\n",
        "        y_pred_tag = torch.round(y_test_pred)\n",
        "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
        "\n",
        "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
        "\n",
        "files_names = list(pd.read_csv('mean_variance_test.csv')['file'])\n",
        "\n",
        "file_predict_dict = {}\n",
        "for i in range(len(y_pred_list)):\n",
        "  file_predict_dict[files_names[i]] = y_pred_list[i]\n",
        "\n",
        "print(file_predict_dict)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Bad 1.mov': 0.0, 'Bad 10.mov': 0.0, 'Bad 11.mov': 0.0, 'Bad 12.mov': 0.0, 'Bad 13.mov': 1.0, 'Bad 14.mov': 1.0, 'Bad 15.mov': 1.0, 'Bad 16.mov': 1.0, 'Bad 2.mov': 0.0, 'Bad 3.mov': 1.0, 'Bad 4.mov': 1.0, 'Bad 5.mov': 0.0, 'Bad 6.mov': 0.0, 'Bad 7.mov': 0.0, 'Bad 8.mov': 0.0, 'Bad 9.mov': 0.0, 'Good 1.mov': 1.0, 'Good 11.mov': 0.0, 'Good 12.mov': 1.0, 'Good 2.mov': 1.0, 'Good 4.mov': 1.0, 'Good 6.mov': 1.0, 'Good 7.mov': 1.0, 'Good 8.mov': 1.0, 'Good 9.mov': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MaH2Hlaneg3"
      },
      "source": [
        ""
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xof09hvynXtS",
        "outputId": "061f4e3d-ad63-4ded-f1a0-0530797b02f7"
      },
      "source": [
        "print(confusion_matrix(y_test, y_pred_list))\n",
        "print(y_test)\n",
        "print(y_pred_list)\n",
        "print(classification_report(y_test, y_pred_list))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10  6]\n",
            " [ 1  8]]\n",
            "0     0\n",
            "1     0\n",
            "2     0\n",
            "3     0\n",
            "4     0\n",
            "5     0\n",
            "6     0\n",
            "7     0\n",
            "8     0\n",
            "9     0\n",
            "10    0\n",
            "11    0\n",
            "12    0\n",
            "13    0\n",
            "14    0\n",
            "15    0\n",
            "16    1\n",
            "17    1\n",
            "18    1\n",
            "19    1\n",
            "20    1\n",
            "21    1\n",
            "22    1\n",
            "23    1\n",
            "24    1\n",
            "Name: class, dtype: int64\n",
            "[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.62      0.74        16\n",
            "           1       0.57      0.89      0.70         9\n",
            "\n",
            "    accuracy                           0.72        25\n",
            "   macro avg       0.74      0.76      0.72        25\n",
            "weighted avg       0.79      0.72      0.72        25\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv0n1ZEIoth_",
        "outputId": "f4727cf8-03ee-4b04-9b99-70d7e7374934"
      },
      "source": [
        "## prediction of Shoulder Press or Bicep Curl \n",
        "\n",
        "bc_test_video_dir = 'Good 2.mov'\n",
        "sp_test_video_dir = 'SP good 1.mov'\n",
        "\n",
        "test_frames,video,prob,label = sequence_prediction(2,bc_test_video_dir)\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  bicep_curl: 50.69%\n",
            "  shoulder_press: 49.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k2htgn4pC1a",
        "outputId": "935f14f1-7f1b-4221-fa97-72730892aa59"
      },
      "source": [
        "## prediction of good or bad\n",
        "\n",
        "good_bad_predictor = file_predict_dict[bc_test_video_dir]\n",
        "if good_bad_predictor == 1:\n",
        "  label_2 = 'good'\n",
        "else:\n",
        "  label_2 = 'bad'\n",
        "\n",
        "print(prob,label,label_2)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.50694805 bicep_curl good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "NsbGnDJ_sx3x",
        "outputId": "53c04823-5003-4437-d31f-f5d17a7f5228"
      },
      "source": [
        "## Writing the output to the video itself for example sake \n",
        "\n",
        "import cv2\n",
        "\n",
        "cap = cv2.VideoCapture(f'./gdrive/MyDrive/data/goodtest/{bc_test_video_dir}')\n",
        "out = cv2.VideoWriter(f'./{video}', -1, 20.0, (640,480))\n",
        "  \n",
        "(grabbed, frame) = cap.read()\n",
        "fshape = frame.shape\n",
        "fheight = fshape[0]\n",
        "fwidth = fshape[1]\n",
        "print(fwidth , fheight)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = cv2.VideoWriter('output.avi',fourcc, 20.0, (fwidth,fheight))\n",
        "\n",
        "while(True):\n",
        "      \n",
        "    # Capture frames in the video\n",
        "    ret, frame = cap.read()\n",
        "  \n",
        "    # describe the type of font\n",
        "    # to be used.\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "  \n",
        "    text_to_display = f'This is a {label} exercise with {prob}% probability\\n this is also an example of a {label_2} {label}'\n",
        "    # Use putText() method for\n",
        "    # inserting text on video\n",
        "    cv2.putText(frame, \n",
        "                text_to_display, \n",
        "                (50, 50), \n",
        "                font, 1, \n",
        "                (0, 255, 255), \n",
        "                2, \n",
        "                cv2.LINE_4)\n",
        "  \n",
        "    # Display the resulting frame\n",
        "    #cv2.imshow()\n",
        "    out.write(frame)\n",
        "  \n",
        "    # creating 'q' as the quit \n",
        "    # button for the video\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "  \n",
        "# release the cap object\n",
        "cap.release()\n",
        "# close all windows\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2880 1800\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-58036203821f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Capture frames in the video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# describe the type of font\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9yfedhzs7fs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}